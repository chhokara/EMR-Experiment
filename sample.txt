export VIRTUAL_CLUSTER_ID=$(aws emr-containers list-virtual-clusters --query "sort_by(virtualClusters, &createdAt)[-1].id" --output text)
export EMR_ROLE_ARN=$(aws iam get-role --role-name ${EMR_ROLE_NAME} --query Role.Arn --output text)

## create job request
cat << EOF > ./request-spark-ml.json
{
    "name": "spark-ml",
    "virtualClusterId": "${VIRTUAL_CLUSTER_ID}",
    "executionRoleArn": "${EMR_ROLE_ARN}",
    "releaseLabel": "emr-6.2.0-latest",
    "jobDriver": {
        "sparkSubmitJobDriver": {
            "entryPoint": "s3://${S3_BUCKET_NAME}/ml-randomforest.py",
            "entryPointArguments": [
                "--data_source", "s3://${S3_BUCKET_NAME}/cleaned-data/",
                "--output_uri", "s3://${S3_BUCKET_NAME}/output"
            ],
            "sparkSubmitParameters": "--conf spark.executor.instances=2 \
                --conf spark.executor.memory=8G \
                --conf spark.executor.cores=2 \
                --conf spark.driver.cores=1 \
                --conf spark.driver.memory=8G"
        }
    },
    "configurationOverrides": {
        "monitoringConfiguration": {
            "cloudWatchMonitoringConfiguration": {
                "logGroupName": "${LOG_GROUP_NAME}",
                "logStreamNamePrefix": "spark-ml"
            },
            "s3MonitoringConfiguration": {
                "logUri": "s3://${S3_BUCKET_NAME}/logs/"
            }
        }
    }
}
EOF

aws emr-containers start-job-run \
    --cli-input-json file://./request-spark-ml.json
